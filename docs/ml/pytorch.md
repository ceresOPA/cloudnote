# Pytorch学习笔记

## 一、人工神经网络VS生物神经网络

- 人工神经网络会预先设置好网络结构，在训练期间网络结构不会改变。通过前向与后向传播，达到预定的效果。其中，通过前向传播，得到预测的结果与真实结果比较，之后通过后向传播进行修正，从而达到预测效果的优化。
- 生物神经网络则是通过对神经的刺激，是会凭空出现神经连接，在形成过程中，神经网络会发生改变。

## 二、什么是神经网络

- 神经网络的训练过程就是调整神经中的权值的过程，根据前向传播的结果，使用后向传播去改变每个神经元的敏感度，让神经网络离正确的结果又接近一点点，然后经过成千上万次的训练，每一次一点点修正，最终达到一个不错的效果。

## 三、梯度下降法（Gradient Descent）

- Gradient Descent属于Optimism问题，即优化问题。
- 梯度下降法其实就是一个求极值的过程，根据梯度下降的方向，不断向极值逼近。
- 但也正因为是求解的极值，因此极有可能找到的并不是也全局最优解(即并不是最值)，往往会是局部最优解，但我们可以尽可能找到一个最好的局部最优解。

## 四、神经网络的隐含层

- 神经网络的中间层（除了输入层和输出层）被称为隐含层，或者说黑盒的原因，在于当输入的特征过多，中间的神经元也过多的时候，我们无法用二维或三维图像进行表示，即没有办法直接观测其中的内容。但是，整个过程是一样的，其中所做的变化在于对特征的抽象，抽象后的特征是计算机可以理解的，并且经过多个中间层，会得到更加有针对性、精简的特征，有利于计算机的识别判断。

## 五、BP神经网络（Back Propagation Neural Network）

- BP神经网络为神经网络的训练提供了方法
- 是一种按照误差反向传播训练的多层反馈神经网络
- 本质上，BP算法就是以**网络误差平方**为目标函数，采用**梯度下降法来计算目标函数的最小值**。