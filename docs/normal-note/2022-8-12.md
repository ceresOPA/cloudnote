# 记第一次复现论文中遇到的问题



一、 模型训练过程中，明明使用了GPU加速，而且还是RTX 3070，按理说对于我那几万条一维的数据，应该跑的挺快的，而且我还是一个比较简单的网络。在查看任务管理器的时候，显示的CPU占用极高，大于70%，内存也是，batchsize完全没法拉大，让我一度怀疑是不是没有跑到GPU上面来。

**解决方案**：经过排查后，发现自己的GPU的占用，是那种跳跃式的，一下很高，一下很低，就猜测是不是其实GPU运算的时候运算的很快，但是因为CPU加载数据很吗？然后就有在想是不是自己的data和label没有加载到GPU上来，但模型是GPU，数据是CPU的话，是会报错的，所以后面查了资料，在DataLoader那里使用了pin_memory和num_workers，提取预加载数据，想着这样应该总行了吧，我都提前加载数据了，但是发现还是不行，通过num_workers，每次能够加载多个batch，而且训练也是一下就跑完了，但又要等一会儿下一次加载的几个batch，到这里其实就已经可以确定，这肯定是我的数据加载还是存在问题，在排查之后，发现，数据加载这块

```python
def __getitem__(self,index):
    label = F.one_hot(torch.Tensor(self.labels_list).to(torch.int64),num_classes=5)[index]

    signal = torch.Tensor(self.signals_list)[:,index*100*30:(index+1)*100*30]
    
    return signal,label
```

在这里，我每次都对所有的数据的进行Tensor类型转变，然后取其中的一段，就挺离谱的，我明明就可以在__init__函数那里完成Tensor转换的这个操作，但我硬是放在了__getitem__去做这件事情。



二、使用了BN层后，在进行模型的测试的时候，使用model.eval()就会导致模型的效果偏差巨大啊？？感觉已经把网上有的方法都试过了，BN层不能重复调用，这个改了，数据的归一化，除非是我的理解问题，我在一开始就对数据进行了归一化，但还是不行，以及batchsize的设置，我就没设置为1过，太玄学了，不能理解，现在只有不采用BN层的网络结构还好，但在测试集上，也只能够恰好达到70%，就一直不往上涨了，太离谱了。改了好几个，都差不多70%。

**解决方案**：好吧，到最后还是归一化的问题，就挺离谱的，只要把训练集、验证集和测试集统一进行归一化后，就什么问题也没有了，但是这里真的很奇怪，不是很能理解进行统一的归一化，直观上来说进行统一的归一化后感觉在测试集上的效果肯定会比之前好，但是这样的操作之后，要是后续有新的数据怎么办，已经没有办法进行统一的归一化了，方差和均值还是会变。麻了。



三、还有关于Loss的问题，在训练到一定次数以后，训练集的loss开始振荡，验证集的loss开始上升，训练集的准确度一直上升，验证集准确度基本不变，这样算是过拟合吗？但是为什么训练集的loss是不断振荡，而不是减下，不懂。

**解决方案**：目前还是不懂，只能说要么是我的网络结构有问题，要么是优化器不合适，要么是损失函数不合适吧，还可能是一些超参数的设置问题，纯猜测，头大，其实一开始几十次迭代还挺正常的，不会抽风一样上下振荡。



四、指标

sensibility（recall）

灵敏度，是指实际为阳性的样本中，判断为阳性的比例

specialty

特异度，针对负样本