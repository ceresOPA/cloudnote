# 数据结构



## 问题篇

### 1. 最短路径

- 最短路径一般分为单源最短路径和多源最短路径，单源最短路径通常会采用迪杰斯特拉算法来进行求解，但迪杰斯特拉只能够应用于非负权值的问题上，迪杰斯特拉算法的时间复杂度为$O(n^2)$；而多源最短路径一般会采用弗罗里达算法，时间复杂度为$O(n^3)$。



### 2. 哨兵和头结点的本质作用？

- 哨兵和头结点本质上都是用来简化代码，使程序更加高效。
- 哨兵可以用来简化边界条件，在循环或者迭代中用来标志终止的值，像顺序查找中，可以让下标为0的数组位置存放本次要查找的元素值，然后从后往前，就只需要判断值是否相等，而不需要去判断当前下标来避免越界，简化了代码。
- 引入头结点后，可以让链表中第一个结点的操作与其他结点保持一致，写在一个循环里面，就比如插入的时候，就不需要单独为插入第一个结点来调整头指针了，而是可以和其他结点的操作步骤一样。



### 3. 堆排序

- 堆排序一般分为大根堆和小根堆，它的一个特点就是下一层的结点大小一定是小于上一次的，然后根结点是最大的或者最小的。
- 一般需要先建堆，然后才能够进行堆排序，自底向上建堆的时间复杂度为$O(n)$，堆排序取$n$个数，每次调整的时间为$logn$，所以堆排序的时间复杂度为$O(nlogn)$。
- 由于堆排序每次都能够确定最大或者最小的元素，因此非常适合从许多元素中选取最大或最小的一些元素的情形。



### 4. 快速排序的时间复杂度，以及如何解决快速排序最快的情形

- 快速排序的最好和平均时间复杂度为$O(nlogn)$，最坏时间复杂度为$O(n^2)$。
- 快排的效率与每次选取的枢轴有关，当每次选取的元素不能够平分两侧的话，就会影响快排的效率，如基本有序的序列，每次选取最前面的元素就会导致最坏的情况，因此只要能够选择合适的枢轴就可以解决最坏的情形，一般可以随机化选择枢轴或者从前、中、后的三个元素中选择大小中间的那个元素，这样即使是有序的情况下，也能够避免最坏的发生。



### 5. 无向图的遍历方法，时间复杂度？

- 深度优先遍历，广度优先遍历
- 时间复杂度与使用的遍历方法无关，而是与所选择的图的存储结构有关，若选择邻接矩阵作为存储结构，则时间复杂度为$O(n^2)$，若选择邻接表作为存储结构，则时间复杂度为$O(V+E)$



### 6. 无向图中两结点的最远距离怎么求？

- 可以类比最短路径，可以使用迪杰斯特拉算法，其中每次选取的是距离最长的路径，而不是最短的



### 7. 队列满空的条件

- 若采用循坏队列，用$i$表示队头，$j$表示队尾，则$(j+1)\%Len == i$表示队满，其中$Len$是循环队列的长度，而$i==j$则表示队空。
- 使用循坏队列可以避免假溢出的发生



### 8. 时间效率为$O(1)$的查找方法

- 哈希查找，哈希查找直接利用关键字访问内存存储位置。将所查找的数据映射导散列表中，其中的映射方法就是使用散列函数(或称哈希函数)
- 常用散列函数：
  - 直接定址法，取关键字或关键字的某个线性函数值为散列地址（$y = x $或 $y = kx+b$）
  - 数字分析法，取关键字的若干数位作为散列地址
  - 平方取中法，取关键字平方后的值的中间几位为散列地址，因为有时并无法判断选择关键字的哪几位比较合适，因此通过平方后的数就与原关键字的每一位都有关系，从而保证散列地址的随机性。
  - 折叠法，将关键字分为数位相同的几个部分，然后取这几部分的叠加和作为散列地址
  - 除留余数法，取关键字被某个不大于表长m的数p(一般取不大于表长的最大素数)除后的余数作为散列地址，即$hash(k) = k\%p （p<=m）$ 
- 常用处理哈希冲突的方法：
  - 拉链法
  - 开放定址法
    - 线性探测法
    - 平方探测法



### 9. 设计算法-找出图的强连通分量



### 10. 有向图可不可以有最小生成树？

- 可以，有向图的最小生成树称为 最小树形图，可以使用 朱刘算法 进行求解。



### 11. 图的边权值有负，要求最短路径，应该怎么解决？

- 因为在迪杰斯特拉算法中，已加入到最短路径中的结点是无法再进行更新的，如果在后面再出现负的权值的到该结点的路径，导致路径之和更小，则没有办法进行更新。
- Floyd算法可以解决有负权值的情形，但是当存在负环的情况下，是无法得到最短路径的，因为通过负环可以无限地小下去。



### 12. 二叉树查找的时间复杂度

- 二叉查找树，即二叉排序树，通过中序遍历即可得到一个有序序列。
- 在二叉排序树是平衡的情况下，查找的时间复杂度与树的深度有关，即$O(logn)$，当二叉排序树是一颗单子树的时候，则与顺序查找的时间复杂度一样$O(n)$。



### 13. 排序算法时间复杂度的下限

- 基数排序



### 14. 举例说明不同数据结构在算法实现时，时间复杂度不同的现象

- 最常见的例子应该就是线性表和链表的插入、删除、查找操作
- 其中对于插入与删除，链表只要找到位置，就只需要$O(1)$就能完成插入和删除；而线性表在插入操作中，删除中间某个元素，需要前移后面的元素，插入操作，需要后移后面的元素留出位置，因此线性表完成插入和删除操作需要$O(n)$的时间复杂度
- 对于查找操作，由于线性表直接通过下标就可以访问所有的元素，即时间复杂度为$O(1)$，而对于链表，需要从头结点开始往下查找，因此时间复杂度为$O(n)$。



### 15. 如何证明一个无向图是双连通的？

- 话说什么叫双连通？？



### 16. 一般树与二叉树的区别

- 二叉树是区分左右孩子的，一般树只表明有几个孩子结点，并没有左右之分。
- 二叉树的每个结点最多只能有两个结点，而一般树无限制。



### 17. 已知先序遍历和后续遍历可以确定唯一的一颗树吗？

- 不可以，无论是先序遍历还是后序遍历都只能确定根结点，而没有办法确定左右结点，要想确定一颗二叉树的话，必须要知道它的中序遍历



### 18. 给你两颗二叉树怎么确定它们的高低？

- 遍历得到树的深度，如先序遍历，递归就可以求出树的深度
- 根据树的深度就可以判断树的高低



### 19. 能用来查询的数据结构，哪种综合性能好，查询和维护都能达到$O(nlogn)$?

- 平衡二叉树
- 红黑树
- 综合来说，平衡二叉树的查找效率更高，但维护代价也更高，而红黑树的调整代价较低，查找效率会稍低一些。



## 归纳篇

### 线性表

#### 1. 顺序表和链表的比较

- **存取方式不同**，顺序表可以支持顺序存取与直接存取，即通过下标可直接查找到对应元素并可修改其值，而链表只能进行顺序存取，需要通过头指针，依次往后查找到对应位置后才能进行存取。
- **逻辑结构和物理结构的对应关系不同**，无论是顺序表还是链表，其中各元素在逻辑上都是连续的。不同的是，顺序表在物理上也是位于连续的存储空间，而链表在物理上并不一定是连续的，逻辑上的连续是通过各结点中的指针来实现的。
- **查找的时间复杂度不同**，按位置进行查找的话，顺序表只需要$O(1)$的时间复杂度，而链表则需要$O(n)$的时间复杂度，如果采用按值查找的话，则都需要$O(n)$的时间复杂度。
- **插入和删除的时间复杂度不同**，顺序表进行插入，除在最后插入外，其他位置插入都需要后移插入位置后面的所有元素，删除，则需要前移后面位置的所有元素，都需要$O(n)$的时间复杂度。对于链表，插入和删除，则只需要$O(1)$的时间复杂度，插入，直接修改前后结点的指针即可，删除，则将删除结点的前一个结点的指针指向删除结点的后一个结点即可。
- **存储空间分配的不同**，顺序表如果采用静态存储分配，则分配的存储空间固定，这会导致分配的少，则不够存储所有元素，分配的多，浪费存储空间；采用动态存储分配，虽然可以动态改变存储空间，但每一次的长度增加，需要移动大量元素，效率低。同时，顺序表需要的是连续的存储空间，若没有足够的连续存储空间同样会分配失败。而对于链表，各结点是通过指针连接的，不需要提前分配存储空间，也不需要连续的存储空间，只要有内存就可以进行分配。

#### 2. 头指针和头结点的区别是什么？

- **头指针**，是链表中必不可少的，它指向链表中的第一个结点，通过头指针，可以遍历链表中的所有元素。
- **头结点**，主要为了能够让第一个元素结点的插入和删除操作与后面的结点是一致的，在第一个元素结点前加入了一个头结点，因此，头结点并不是必须的。同时，头结点中的数据域可以不存储数据，也可以用来存储链表的长度。

### 字符串匹配

#### 1. KMP算法

- 主串不回溯，子串回溯
- next数组

#### 2. BM算法

- 后缀匹配

### 树

#### 1. 对于先序、中序、后序与层次遍历，怎样才能够构建一颗唯一的二叉树？

答：只要已知中序和其他任意三种遍历中的一种就可以实现确定唯一一颗二叉树。

解析：已知先序、后序或者层次中的任意种，就可以确定这颗树的根结点；已知中序遍历，就可以知道根的左右结点；把这颗二叉树看成是多颗小二叉树，这样就可以确定好每个根结点及其左右结点，最终确定整个大二叉树的结构。

#### 2. 如何进行二叉排序树的删除？

答：一共三种情形：	

​		① 删除结点是叶子结点：**直接删除**就可以了，不会破坏二叉排序树的结构

​		② 删除结点有左子树或右子树：**让删除结点的父结点指向删除结点的左子树或右子树**，因为如果只有左子树，那中序遍历最后访问			的是删除的结点，如果只有右子树，那中序遍历最先访问的就是删除的结点。

​		③ 删除结点既有左子树又有右子树：让删除结点与其中序遍历的前驱或者后驱结点交换，然后删除前驱或后驱结点。

### 图

#### 1. 最短路径问题

##### 1. 迪杰斯特拉算法

- 用于解决**单源**最短路径问题，即求出从某一点出发，到其他所有顶点的最短路径
- 迪杰斯特拉算法采用**贪心**的策略，声明一个数组用于保存源点和各个顶点之间的距离，以及一个用于存放已找到最短路径的顶点的数组。每次选择路径最短的顶点加入最短路径的数组，然后通过已加入到最短路径的顶点更新路径，再重复找最短路径的顶点，直至所有顶点加入最短路径数组为止。
- 迪杰斯特拉算法只适用于**路径权值为正**的图，如果存在为负的权值的路径，则会存在有可能之前找到的最短路径并不是真正的最短路径，后面还有更短的，或者对于负权值环的情况，则永远也找不到最短路径。
- 时间复杂度为$O(n^2)$，如果想要求从每个顶点出发的最短路径，即多源最短路径，则可循环以每个顶点为源点，时间复杂度为$O(n^3)$

- **迪杰斯特拉算法的优化问题**，算法中最耗时的部分的在于每次遍历找最短路径，如果用优先队列（感觉用小根堆也许）来存放距离，每次顶部top的即是最小的距离，这样可以降低时间复杂度。

##### 2. 弗罗里达算法

- 可以解决**多源**最短路径问题
- 边的权值**允许有负值**
- 弗罗里达算法采用**动态规划**的思想，声明一个map矩阵和一个path矩阵，map矩阵，用于存储各顶点之间的距离，每次选择一个顶点作为中间顶点，若得到的距离比原距离更小，则更新map矩阵的距离，以及path矩阵对应的顶点。
- 时间复杂度为$O(n^3)$

#### 2. 最小生成树

##### 1. Prim算法

- 从某一顶点出发，选择与其相关的最小权值的边，同时，将对应的顶点加入顶点集中，之后类似找与顶点集中顶点相关联的最小权值的边，再同样的将对应的顶点加入顶点集中，直到将所有的顶点都加入为止。
- Prim算法适合于边稠密的图，因为它的时间复习度只依赖于顶点，与边无关。
- 时间复杂度为$O(|V|^{2})$，与边$E$无关

##### 2. 克鲁斯卡尔算法

- 每次从图中所有的边中选择权值最小的边，若与该边相连的顶点不在一个连通子图上，则将其加入顶点集，并记录下边，若最小的边对应的两个顶点在同一个连通子图上，则不选择该边，重新选择其他边。
- 适合于边稀疏顶点多的图
- 克鲁斯卡尔采用堆来取边$O(log|E|)$，采用并查集来添加边$O(|E|)$，所以克鲁斯卡尔的时间复杂度为$O(|E|log|E|)$。

##### 3. 关于最小生成树的补充

- Prim和克鲁斯卡尔都是采用贪心的思想

- 即使存在权值全相同的图，它的最小生成树也可能唯一，如当图本身就是一颗树的时候。

### 查找

#### 1. 顺序查找

- 时间复杂度为$O(n)$
- 可以将下标为0的位置作为哨兵，存放本次查找的元素，之后从后往前查找，若查找至0的位置，则说明该元素不存在，反之，返回对应位置。也就是说，利用哨兵，可以避免边界判断的问题，简化代码。

#### 2. 二分查找

- 前提：**一定要是有序序列**

- 构建二分查找树，查找的时间复杂度为$O(logn)$

- 每次比较与中间元素的大小关系，如果大，则往右找，小则往左找。

#### 3. 二叉排序树查找

- 二叉排序树的特点在于，左小于根，小于右，即可以通过中序遍历得到一个有序序列。
- 二叉排序树是动态可改变的，若不存在，则可插入至二叉排序树中。
- 平均时间复杂度为$O(logn)$，最坏的情况下，即单子树的时候，时间复杂度为$O(n)$

#### 4. 哈希查找

- 哈希表的构建
  - 直接定址法，元素地址与元素之间为线性关系，即取某一个线性函数作为哈希函数。
  - 数字分析法，选取元素中的某些数字作为地址，尽可能保证分布均匀，避免冲突。
  - 平方取中法，由于大部分时候并没法确定应该选择哪几个数字，那么就可以通过平方的方法来综合考虑所有的数字，然后选择平方后的数字的中间几位作为地址。
  - 折叠法，将数字分为相同大小的几个部分的，将各部分相加作为地址。
  - **除留余数法**，最常用的方法。$hash(k) = k\%p （p<=m）$ ,其中k表示元素的值，p表示不大于表长的最大素数。
- 解决冲突的方法
  - 开放定址法
    - 线性探测法，发生冲突后，探测+1，+2，+3...，是否有元素，若无，则存放
    - 平方探测法，与线性探测法类似，只是探测位置有些许不同，+1，-1，+4，-4，+8，-8，$i^2$

### 排序

#### 1. 直接插入排序

- 直接插入排序对于基本有序的序列，时间复杂度可以达到$O(n)$，平均时间复杂度为$O(n^2)$
- 直接插入排序也可以在下标为0的位置设置哨兵，同样可以避免边界判断的问题，如从小到大的排序，一直与有序的一侧比较，没有比当前元素小的，则会直接放在首位。
- 属于**稳定排序**
- 每次不能确定一个元素在最终位置。

#### 2. 折半插入排序

- 直接插入排序的改进版，优化的部分在于能够更快地找到有序部分的插入位置。
- 时间复杂度仍然为$O(n^2)$，因为虽然能够更快地找到插入位置，但是数组插入时的移动仍然需要时间。
- 属于**稳定排序**
- 每次不能确定一个元素在最终位置。

#### 3. 希尔排序

- 时间复杂度为$O(n^{1.3})$，插入排序的改进版
- 希尔排序中，按步长进行排序，一般初始步长选取为序列长度的一半d，之后每次补充减1，直至d为1时，则序列可实现有序。
- **不稳定排序**，因为是按照步长进行排序的，有可能会导致后面的相同元素被替换到前面去。
- 每次不能确定一个元素在最终位置。

#### 4. 选择排序

- 思想比较简单，每次从无序的部分选择最小的那个元素，放在最终的位置，时间复杂度为$O(n^2)$
- **不稳定排序**，如对于序列<font color=blue>2</font> 2 1，则第一趟之后变为1 2 <font color=blue>2</font> ，即原本前面的2被换到了后面。
- 每次可以确定一个元素在最终位置。

#### 5. 快速排序

- 快排采用分治的思想，每次选择一个枢轴，通过交换，让枢轴左边的元素都比它小，右边的元素都比他大，这样就确定了枢轴元素的最终位置。
- 快排的平均时间复杂度为$O(nlogn)$，由于快排采用递归的方式，因此空间复杂度为栈的深度$O(n)$。
- 快排最坏的情况下时间复杂度会到达$O(n^2)$，即如果序列基本有序，选择的枢轴每次为第一个位置的元素，则会造成最坏的情况。
- 快排枢轴元素的选择会影响快排的效率，因此可以通过一定的策略来进行枢轴元素的选择，如通过随机选择枢轴或从前、中、后三个元素中选择大小中间的那个元素作为枢轴，来改进快排。
- 快排属于**不稳定排序**，但每次可以确定一个元素在最终的位置。

#### 6. 冒泡排序

- 冒泡排序以从左往右依次递增排序举例，每一趟都进行两两比较，让大的元素不断往前走，这其实就是冒泡的过程，这样每次都能够让最大的元素到达最终的位置。

- 冒泡排序在序列基本有序的情况下，借助flag标志，时间复杂度可达到$O(n)$。flag的作用在于，当某一轮中不存在任何元素交换，则说明序列已经有序，则不需要再循环下去了。
- 冒泡排序的平均时间复杂度为$O(n^2)$，属于**稳定排序**，每次能够确定一个元素的最终位置。

#### 7. 堆排序

- 堆的建立
  - 建堆的时间复杂度可以达到$O(n)$，从最后一个元素的双亲结点开始不断往前调整，完成建堆。
- 堆排序
  - 堆排序每次可以确定一个最大或最小的元素，因此特别适合于大数据中选取前n个元素的情况。
  - 推排序中，每次从根结点取出元素后，让最后一个叶子结点替代根结点，之后逐次向下调整，因此若取n个元素，堆排序的时间复杂度为$O(nlogn)$
- 不稳定排序，因为会进行交换位置。每次能够确定一个元素的最终位置。

#### 8. 归并排序

- 把两个或两个以上的有序表合并成为一个新的有序表
- 时间复杂度为$O(nlogn)$，属于稳定排序，但每轮不能够一个元素的最终位置。

#### 9. 基数排序

- 对于n个元素进行基数排序的时间复杂度为$O(d(n+rd))$，其中每一趟分配的时间复杂度为$O(n)$，回收的时间复杂度为$O(rd)$，一共要进行$d$趟。
- 属于稳定排序。







